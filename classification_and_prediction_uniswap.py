# -*- coding: utf-8 -*-
"""Copy of Copy of CLASSIFICATION_OF_ATTACKS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tfv_5rfAF8DPtlrbFHqFu15fATvIRYgg
"""

import pandas as pd

swapData = pd.read_csv("uniswap_eth_swap.csv")
swapData

swapData.columns

# remove duplicated rows, if there's any only for Transactions:
swapData = swapData.drop_duplicates(subset=["tx_hash"],keep="first")

# sort value by block_number first, then log_index
swapData = swapData.sort_values(['block_number', 'log_index'], ascending = [True, True])

# only look at transactions that have swapped non-zero tokens
validSwaps = swapData[abs(swapData['amount0'])>0]
validSwaps = validSwaps.reset_index(drop=True)
validSwaps
#swapData['tx_hash']

totalRevenue = {}
totalCost = {}
sandwichTrader = {}
totalProfit = {}

for block_number in validSwaps['block_number'].unique():
    blockData = validSwaps[validSwaps['block_number']==block_number]

    if len(blockData) > 2: # >=3 swap txs in a block
        senders = blockData['sender']
        for sender in senders.unique():
            senderSwapData = blockData[blockData['sender']==sender]
            if len(senderSwapData) == 2: # more than 1 tx in a block
                sandwichStartIndex = senderSwapData.iloc[0].name

                sandwichedSwap = blockData.loc[sandwichStartIndex+1] # the starting index of the potential sandwich
                # three criteria to see if it's a sandwich attack
                withMiddleTx = senderSwapData.iloc[0].name == senderSwapData.iloc[-1].name - 2 # if there's a middle tx
                sameTradingFlow = sandwichedSwap['amount1'] * senderSwapData.iloc[0]['amount1'] > 0 # same direction
                withCloseTradeTx = senderSwapData.iloc[0]['amount1'] * senderSwapData.iloc[-1]['amount1'] < 0 # different direction

                if withMiddleTx and sameTradingFlow and withCloseTradeTx:

                    # calculate start and end price
                    ethStartPrice = abs(senderSwapData.iloc[0]['amount0'] / senderSwapData.iloc[0]['amount1'])
                    ethEndPrice = abs(senderSwapData.iloc[-1]['amount0'] / senderSwapData.iloc[-1]['amount1'])

                    # calculate gas cost
                    startGasFee = ethStartPrice * senderSwapData.iloc[0]['gasUsed'] * senderSwapData.iloc[0]['gasPrice'] / 1e18
                    endGasFee = ethEndPrice * senderSwapData.iloc[-1]['gasUsed'] * senderSwapData.iloc[-1]['gasPrice'] / 1e18
                    cost = (startGasFee + endGasFee)
                    if senderSwapData.iloc[0]['amount1'] < 0: # sell ETH first, buy it back later
                        revenue = (ethStartPrice - ethEndPrice) * abs(senderSwapData.iloc[0]['amount1'])

                    else:  # buy ETH first, sell it later
                        revenue = (ethEndPrice - ethStartPrice) * abs(senderSwapData.iloc[0]['amount1'])

                    sandwichTime = senderSwapData.iloc[0]['block_time']

                    print(sandwichTime)
                    totalRevenue[sandwichTime] = revenue
                    totalCost[sandwichTime] = cost
                    totalProfit[sandwichTime] = revenue - cost
                    sandwichTrader[sandwichTime] = sender

totalDf = pd.DataFrame.from_dict(totalRevenue, orient='index')
totalDf.columns = ['Sandwich Revenue']
totalDf['Sandwich Cost'] = list(totalCost.values())
totalDf['Sandwich Profit'] = list(totalProfit.values())

totalDf['Cumulative Sandwich Revenue'] = totalDf['Sandwich Revenue'].cumsum()
totalDf['Cumulative Sandwich Cost'] = totalDf['Sandwich Cost'].cumsum()
totalDf['Cumulative Sandwich Profit'] = totalDf['Sandwich Profit'].cumsum()
totalDf['Sandwich Trader'] = list(sandwichTrader.values())
totalDf

backRunTx = {}   # dictionary to store back-run transactions
backRunners = set()  # set to store back-running traders
df=swapData
for i, tx in df.iterrows():

    # only consider transactions with non-zero gas price and gas used
    if tx['gasPrice'] == 0 or tx['gasUsed'] == 0:
        continue

    # find other transactions with the same sender and recipient
    other_txs = df[(df['sender'] == tx['sender']) & (df['recipient'] == tx['recipient']) & (df['tx_hash'] != tx['tx_hash'])]

    # check if any of these other transactions have a lower gas price and earlier block time
    for j, other_tx in other_txs.iterrows():
        if other_tx['gasPrice'] < tx['gasPrice'] and other_tx['block_time'] < tx['block_time']:
            # if so, add the transaction to the backRunTx dictionary and the sender to the backRunners set
            backRunTx[tx['tx_hash']] = (other_tx['tx_hash'], other_tx['gasPrice'], other_tx['block_time'])
            backRunners.add(other_tx['sender'])
            break

# print the results
print("Number of back-run transactions found:", len(backRunTx))
print("Number of back-running traders found:", len(backRunners))
print("Back-run transactions:")
for k, v in backRunTx.items():
    print(k, "back-run by", v[0], "with gas price", v[1], "and block time", v[2])

backRunRevenue = {}
backRunCost = {}
backRunProfit = {}

for tx_hash, (other_tx_hash, other_gas_price, other_block_time) in backRunTx.items():
    # find the buy and sell transactions
    buy_tx = df[(df['tx_hash'] == tx_hash) & (df['amount1'] > 0)]
    sell_tx = df[(df['tx_hash'] == other_tx_hash) & (df['amount1'] < 0)]

    if buy_tx.empty or sell_tx.empty:
      continue

    start_price = abs(buy_tx.iloc[0]['amount0'] / buy_tx.iloc[0]['amount1'])
    end_price = abs(sell_tx.iloc[0]['amount0'] / sell_tx.iloc[0]['amount1'])


    # calculate start and end prices
    start_price = abs(buy_tx.iloc[0]['amount0'] / buy_tx.iloc[0]['amount1'])
    if len(sell_tx) > 0:
        end_price = abs(sell_tx.iloc[0]['amount0'] / sell_tx.iloc[0]['amount1'])
    else:
        # handle empty DataFrame case
        end_price = 0

    # calculate gas cost
    gas_cost = buy_tx.iloc[0]['gasPrice'] * buy_tx.iloc[0]['gasUsed'] / 1e18

    # calculate gas fee
    gas_fee = 0
    if len(sell_tx) > 0:
        gas_fee = other_gas_price * sell_tx.iloc[0]['gasUsed'] / 1e18

    # calculate cost
    cost = gas_cost + gas_fee

    # calculate revenue
    revenue = (end_price - start_price) * abs(buy_tx.iloc[0]['amount1'])

    backRunTime = buy_tx.iloc[0]['block_time']

    # add to dictionaries
    backRunRevenue[backRunTime] = backRunRevenue.get(backRunTime, 0) + revenue
    backRunCost[backRunTime] = backRunCost.get(backRunTime, 0) + cost
    backRunProfit[backRunTime] = backRunProfit.get(backRunTime, 0) + revenue - cost

#print("Back-run revenue:")
#for time, revenue in backRunRevenue.items():
 # print(f"Time: {time}, Revenue: {revenue}")

#print("Back-run cost:")
#for time, cost in backRunCost.items():
 # print(f"Time: {time}, Cost: {cost}")

#print("Back-run profit:")
#for time, profit in backRunProfit.items():
 # print(f"Time: {time}, Profit: {profit}")

backRunDf = pd.DataFrame.from_dict(backRunRevenue, orient='index')
backRunDf.columns = ['Backrunning Revenue']
backRunDf['Backrunning Cost'] = list(backRunCost.values())
backRunDf['Backrunning Profit'] = list(backRunProfit.values())

backRunDf['Cumulative Backrunning Revenue'] = backRunDf['Backrunning Revenue'].cumsum()
backRunDf['Cumulative Backrunning Cost'] = backRunDf['Backrunning Cost'].cumsum()
backRunDf['Cumulative Backrunning Profit'] = backRunDf['Backrunning Profit'].cumsum()

backRunDf.head()

frontRunTx = {} # dictionary to store front-run txs
frontRunners = set() # set of front-runners
df=swapData
# iterate over all transactions
for i, tx in df.iterrows():

    # only consider transactions with non-zero gas price and gas used
    if tx['gasPrice'] == 0 or tx['gasUsed'] == 0:
        continue

    # find other transactions with the same sender and recipient
    other_txs = df[(df['sender'] == tx['sender']) & (df['recipient'] == tx['recipient']) & (df['tx_hash'] != tx['tx_hash'])]

    # check if any of these other transactions have a higher gas price and earlier block time
    for j, other_tx in other_txs.iterrows():
        if other_tx['gasPrice'] > tx['gasPrice'] and other_tx['block_time'] < tx['block_time']:
            # if so, add the transaction to the frontRunTx dictionary and the sender to the frontRunners set
            frontRunTx[tx['tx_hash']] = (other_tx['tx_hash'], other_tx['gasPrice'], other_tx['block_time'])
            frontRunners.add(other_tx['sender'])
            break

# print the results
print(f"Number of front-run transactions found: {len(frontRunTx)}")
print(f"Number of front-running traders found: {len(frontRunners)}")
print("Front-run transactions:")

#for tx_hash, (other_tx_hash, other_gas_price, other_block_time) in frontRunTx.items():
#    print(f"{tx_hash} was front-run by {other_tx_hash} with gas price {other_gas_price} and block time {other_block_time}")

frontRunRevenue = {}
frontRunCost = {}
frontRunProfit = {}

for tx_hash, (other_tx_hash, other_gas_price, other_block_time) in frontRunTx.items():
    # find the buy and sell transactions
    buy_tx = df[(df['tx_hash'] == tx_hash) & (df['amount1'] > 0)]
    sell_tx = df[(df['tx_hash'] == other_tx_hash) & (df['amount1'] < 0)]

    if buy_tx.empty or sell_tx.empty:
        continue

    start_price = abs(buy_tx.iloc[0]['amount0'] / buy_tx.iloc[0]['amount1'])
    end_price = abs(sell_tx.iloc[0]['amount0'] / sell_tx.iloc[0]['amount1'])

    # calculate gas cost
    gas_cost = buy_tx.iloc[0]['gasPrice'] * buy_tx.iloc[0]['gasUsed'] / 1e18

    # calculate gas fee
    gas_fee = 0
    if len(sell_tx) > 0:
        gas_fee = other_gas_price * sell_tx.iloc[0]['gasUsed'] / 1e18

    # calculate cost
    cost = gas_cost + gas_fee

    # calculate revenue
    revenue = (end_price - start_price) * abs(buy_tx.iloc[0]['amount1'])

    frontRunTime = buy_tx.iloc[0]['block_time']

    # add to dictionaries
    frontRunRevenue[frontRunTime] = frontRunRevenue.get(frontRunTime, 0) + revenue
    frontRunCost[frontRunTime] = frontRunCost.get(frontRunTime, 0) + cost
    frontRunProfit[frontRunTime] = frontRunProfit.get(frontRunTime, 0) + revenue - cost

frontRunDf = pd.DataFrame.from_dict(frontRunRevenue, orient='index')
frontRunDf.columns = ['Front-running Revenue']
frontRunDf['Front-running Cost'] = list(frontRunCost.values())
frontRunDf['Front-running Profit'] = list(frontRunProfit.values())

frontRunDf['Cumulative Front-running Revenue'] = frontRunDf['Front-running Revenue'].cumsum()
frontRunDf['Cumulative Front-running Cost'] = frontRunDf['Front-running Cost'].cumsum()
frontRunDf['Cumulative Front-running Profit'] = frontRunDf['Front-running Profit'].cumsum()

frontRunDf.head()

# create a copy of the original dataframe
df_with_attack_type = validSwaps.copy()

# get the unique block times where sandwich attacks have happened
sandwichBlocks = set(totalRevenue.keys())
backRunBlocks = set(backRunRevenue.keys())
frontRunBlocks=set(frontRunRevenue.keys())

# function to apply on each row of the dataframe to get the attack type
def get_attack_type(row):
    if row['block_time'] in sandwichBlocks:
        return 'S'
    elif row['block_time'] in backRunBlocks:
        return 'B'
    elif row['block_time'] in frontRunBlocks:
        return 'F'
    else:
        return None



# add a new column 'type_of_attack' to the dataframe
df_with_attack_type['type_of_attack'] = df_with_attack_type.apply(get_attack_type, axis=1)

# filter the dataframe to show only the rows with 'S' in the 'type_of_attack' column
df_sandwich = df_with_attack_type[df_with_attack_type['type_of_attack'] == 'S']
df_sandwich

df_backrun = df_with_attack_type[df_with_attack_type['type_of_attack'] == 'B']

# display the filtered rows
df_backrun

df_frontrun = df_with_attack_type[df_with_attack_type['type_of_attack'] == 'F']
df_frontrun

import pandas as pd

# concatenating the tables `df_sandwich` and `df_backrun`
df_combined = pd.concat([df_sandwich, df_backrun,df_frontrun])
df_combined

from sklearn.utils import resample
df=df_combined
# Separate majority and minority classes
df_majority = df[df.type_of_attack != 'S']
df_minority = df[df.type_of_attack == 'S']

# Upsample minority class
df_minority_upsampled = resample(df_minority,
                                 replace=True,     # sample with replacement
                                 n_samples=len(df_majority),  # to match majority class
                                 random_state=42)  # reproducible results

# Combine majority class with upsampled minority class
df_upsampled = pd.concat([df_majority, df_minority_upsampled])

# Check the class distribution
df_upsampled.type_of_attack.value_counts()

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df_combined['target'] = le.fit_transform(df_combined['type_of_attack'])

import seaborn as sns
sns.heatmap(df_combined.corr(),annot=True)

df_combined.columns



from sklearn.model_selection import train_test_split

df_combined['sqrt_price_x96'] = pd.to_numeric(df_combined['sqrt_price_x96'], errors='coerce')
df_combined = df_combined.dropna()

# Split dataset into features and target variable
X = df_combined[['amount0', 'amount1', 'price', 'gasUsed', 'gasPrice','tick','liquidity','block_time','sqrt_price_x96']]
y = df_combined['type_of_attack']

# Split dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


#X = X.drop('pool', axis=1)

"""RANDOM FOREST"""

from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint as sp_randint
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Define hyperparameter ranges to search over
param_dist = {"max_depth": [3, None],
              "max_features": sp_randint(1, 5),
              "min_samples_split": sp_randint(2, 11),
              "min_samples_leaf": sp_randint(1, 11),
              "bootstrap": [True, False],
              "n_estimators": sp_randint(50, 201)}

# Initialize the model
model = RandomForestClassifier(random_state=42)

# Perform randomized search
random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=50, cv=5, random_state=42)
random_search.fit(X_train, y_train)

# Print the best hyperparameters found
print("Best hyperparameters found:", random_search.best_params_)

# Train the model with the best hyperparameters
model = RandomForestClassifier(**random_search.best_params_, random_state=42)
model.fit(X_train, y_train)

# Predict the labels of the test set
y_pred = model.predict(X_test)

# Evaluate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Generate and print the confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion matrix:\n", conf_matrix)

# Generate and print the classification report
class_report = classification_report(y_test, y_pred)
print("Classification report:\n", class_report)

import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder

# Load the trained classifier and label encoder
model = RandomForestClassifier(**random_search.best_params_, random_state=42)
le = LabelEncoder()
le.fit(df_combined['type_of_attack'])

# Split dataset into features and target variable
X = df_combined[['amount0', 'amount1', 'price', 'gasUsed', 'gasPrice','tick','liquidity','block_time','sqrt_price_x96']]
y = df_combined['type_of_attack']

# Fit the model with the training data
model.fit(X, y)

# Select a random transaction from your dataset
random_transaction = df_combined.sample(1)

# Create a dataframe containing the features of the selected transaction
transaction_features = random_transaction[['amount0', 'amount1', 'price', 'gasUsed', 'gasPrice','tick','liquidity','block_time','sqrt_price_x96']]

# Predict the attack type of the transaction
predicted_label = model.predict(transaction_features)

# Decode the predicted label using the label encoder
#predicted_attack_type = le.inverse_transform(predicted_label)

# Print the predicted attack type
print("Predicted Attack Type:", predicted_label)
# Get the actual label of the selected transaction
actual_label = random_transaction['type_of_attack'].values[0]

# Print the actual label
print("Actual Attack Type:", actual_label)

"""DECISION TREES

"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV

# Initialize the model
model = DecisionTreeClassifier(random_state=42)

# Define the hyperparameter grid to search over
param_grid = {
    'criterion': ['gini', 'entropy'],
    'max_depth': [None, 5, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['auto', 'sqrt', 'log2']
}

# Initialize the grid search object
grid_search = GridSearchCV(model, param_grid=param_grid, cv=5, n_jobs=-1)

# Fit the grid search to the data
grid_search.fit(X_train, y_train)

# Print the best hyperparameters found
print("Best hyperparameters found:", grid_search.best_params_)

# Train the model with the best hyperparameters
best_model = grid_search.best_estimator_
best_model.fit(X_train, y_train)

# Predict the labels of the test set
y_pred = best_model.predict(X_test)

# Evaluate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Generate and print the confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion matrix:\n", conf_matrix)

# Generate and print the classification report
class_report = classification_report(y_test, y_pred)
print("Classification report:\n", class_report)

"""LOGISTIC REGRESSION"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix

# Initialize the model
lr_clf = LogisticRegression(random_state=42, multi_class='multinomial', solver='lbfgs', max_iter=1000)

# Train the model
lr_clf.fit(X_train, y_train)

# Predict the labels of the test set
y_pred = lr_clf.predict(X_test)

# Evaluate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Print the confusion matrix
#cm = confusion_matrix(y_test, y_pred)
#print("Confusion matrix:\n", cm)

"""GRADIENT BOOSTING"""

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report

# Initialize the model
gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=42)

# Train the model
gb_clf.fit(X_train, y_train)

# Predict the labels of the test set
y_pred = gb_clf.predict(X_test)

# Evaluate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Generate a classification report
report = classification_report(y_test, y_pred)
print("Classification Report:\n", report)

#confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion matrix:\n", cm)

"""XGBOOST"""

from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

# Convert non-numeric classes to numeric classes
le = LabelEncoder()
y_train = le.fit_transform(y_train)
y_test = le.transform(y_test)

# Initialize the model
xgb_clf = XGBClassifier(random_state=42)

# Train the model
xgb_clf.fit(X_train, y_train)

# Predict the labels of the test set
y_pred = xgb_clf.predict(X_test)

# Evaluate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

"""MULTILAYER PERCEPTRON(MLP)"""

from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score

# Initialize the model
mlp_clf = MLPClassifier(hidden_layer_sizes=(50,50,50), max_iter=1000)

# Train the model
mlp_clf.fit(X_train, y_train)

# Predict the labels of the test set
y_pred = mlp_clf.predict(X_test)

# Evaluate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

"""ARTIFICIAL NEURAL NETWORKS(ANN)"""

from sklearn.preprocessing import LabelEncoder
from keras.utils import to_categorical

# Split dataset into features and target variable
X = df_combined[['amount0', 'amount1', 'price', 'gasUsed', 'gasPrice']]
y = df_combined['type_of_attack']

# Encode the target variable using LabelEncoder
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# Perform one-hot encoding on the encoded target variable
y_train_one_hot = to_categorical(y_encoded)

# Split dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y_train_one_hot, test_size=0.2, random_state=42)



from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import Adam

# Define the model
model = Sequential()
model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))
model.add(Dropout(0.2))
model.add(Dense(32, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(y_train_one_hot.shape[1], activation='softmax'))

# Compile the model
optimizer = Adam(learning_rate=0.001)
model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, validation_split=0.3, epochs=50, batch_size=32)

# Evaluate the model on the test set
loss, accuracy = model.evaluate(X_test, y_test)
print("Accuracy:", accuracy)

"""ROC CURVE ( NEED TO PREPROCESS DATA AND TUNE THE HYPERPARAMETERS)"""

# from sklearn.metrics import roc_curve, auc
# from sklearn.preprocessing import label_binarize
# from itertools import cycle
# import matplotlib.pyplot as plt

# # Binarize the output
# y_test_bin = label_binarize(y_test, classes=['S', 'B', 'F'])
# n_classes = y_test_bin.shape[1]

# # Train the model
# model.fit(X_train, y_train)

# # Predict probabilities of each class
# y_score = model.predict_proba(X_test)
# labels=['S','B','F']
# # Compute ROC curve and ROC area for each class
# fpr = dict()
# tpr = dict()
# roc_auc = dict()
# for i in range(n_classes):
#     fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])
#     roc_auc[i] = auc(fpr[i], tpr[i])

# # Compute micro-average ROC curve and ROC area
# fpr["micro"], tpr["micro"], _ = roc_curve(y_test_bin.ravel(), y_score.ravel())
# roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])

# # Plot ROC curves for each class
# plt.figure()
# lw = 2
# colors = cycle(['blue', 'red', 'green'])
# for i, color in zip(range(n_classes), colors):
#     plt.plot(fpr[i], tpr[i], color=color, lw=lw,
#              label='ROC curve (area = %0.2f) for class %s' % (roc_auc[i], labels[i]))
# plt.plot([0, 1], [0, 1], 'k--', lw=lw)
# plt.xlim([0.0, 1.0])
# plt.ylim([0.0, 1.05])
# plt.xlabel('False Positive Rate')
# plt.ylabel('True Positive Rate')
# plt.title('Receiver operating characteristic (ROC)')
# plt.legend(loc="upper left")
# plt.show()

